<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    <title>NAMI AI ASSISTANT</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" rel="stylesheet"/>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            height: 100vh;
            overflow: hidden;
            background: #0a0a0a;
        }
        @keyframes pulse {
            0% { opacity: 0.4; transform: scale(0.95); }
            50% { opacity: 1; transform: scale(1); }
            100% { opacity: 0.4; transform: scale(0.95); }
        }
        .speaking-animation {
            animation: pulse 1.5s ease-in-out infinite;
        }
        #conversationContainer::-webkit-scrollbar {
            width: 4px;
        }
        #conversationContainer::-webkit-scrollbar-track {
            background: #1a1a1a;
        }
        #conversationContainer::-webkit-scrollbar-thumb {
            background: #3b82f6;
            border-radius: 2px;
        }
        .animate-fade-in-up {
            animation: fadeInUp 0.3s ease-out;
        }
        @keyframes fadeInUp {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .hidden { display: none; }
    </style>
</head>
<body class="text-white flex flex-col">
  
    <div class="w-full flex justify-between items-center p-4 border-b border-gray-800 bg-black/80 backdrop-blur-lg">
        <div class="text-center w-full">
            <p class="text-gray-400 text-sm font-medium tracking-wide" id="statusText">Tap the mike icon and you ready to go</p>
        </div>
    </div>

    
    <div id="mainContent" class="flex-1 w-full overflow-hidden flex items-center justify-center">
        <div id="conversationContainer" class="h-[70vh] w-full max-w-2xl overflow-y-auto p-4 space-y-4">
            
        </div>
    </div>

    
    <div class="w-full p-6 border-t border-gray-800 bg-black/80 backdrop-blur-lg">
        <div class="flex items-center justify-center gap-4">
            <button class="w-12 h-12 bg-gray-800/50 rounded-full flex items-center justify-center 
                      hover:bg-gray-700/50 transition-all backdrop-blur-sm"
                    onclick="stopResponse()"
                    id="stopButton">
                <i class="fas fa-stop text-gray-300"></i>
            </button>
            
            <button class="relative group" id="micButton" onclick="toggleListening()">
                <div class="w-20 h-20 bg-gradient-to-br from-blue-500 to-purple-600 rounded-full flex items-center justify-center 
                    shadow-2xl transition-all duration-300 transform hover:scale-105 speaking-animation">
                    <i class="fas fa-microphone text-xl text-white"></i>
                </div>
                <div id="loadingIndicator" class="hidden absolute inset-0 bg-white/10 rounded-full backdrop-blur-sm"></div>
            </button>

            <button class="w-12 h-12 bg-gray-800/50 rounded-full flex items-center justify-center 
                      hover:bg-gray-700/50 transition-all backdrop-blur-sm"
                    onclick="togglePause()"
                    id="pauseButton">
                <i class="fas fa-pause text-gray-300"></i>
            </button>
        </div>
    </div>

    <script>
        const API_KEY = "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";
let recognition;
let synthesis;
let isListening = false;
let isSpeaking = false;
let isPaused = false;
let abortController = new AbortController();

// UI Functions
function toggleLoading(show) {
    document.getElementById('loadingIndicator').classList.toggle('hidden', !show);
    const micButton = document.getElementById('micButton');
    if (show) {
        micButton.querySelector('div').classList.add('speaking-animation');
    } else {
        micButton.querySelector('div').classList.remove('speaking-animation');
    }
}

function scrollToBottom() {
    const container = document.getElementById('conversationContainer');
    container.scrollTop = container.scrollHeight;
}

function createMessageElement(content, isUser = false) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `w-full flex justify-center animate-fade-in-up`;
    
    const escapedContent = content
        .replace(/\\/g, '\\\\')
        .replace(/'/g, "\\'")
        .replace(/"/g, '\\"')
        .replace(/\n/g, '\\n')
        .replace(/\r/g, '\\r');
    
    messageDiv.innerHTML = `
        <div class="w-full max-w-xl p-4 rounded-2xl ${
            isUser ? 'bg-gray-800' : 'bg-gray-700'
        }">
            <div class="flex items-start gap-3">
                <div class="flex-shrink-0 w-8 h-8 rounded-full flex items-center justify-center">
                    ${
                        isUser
                        ? '<i class="fas fa-user text-white text-sm bg-gray-600 w-8 h-8 rounded-full flex items-center justify-center"></i>'
                        : `<img src="https://i.pinimg.com/736x/fe/4d/23/fe4d23e351d1fec9e404a812f4b30d8c.jpg" alt="NAMI AI" class="w-8 h-8 rounded-full">`
                    }
                </div>
                <div class="flex-1 min-w-0">
                    <p class="text-sm font-medium ${
                        isUser ? 'text-gray-300' : 'text-blue-300'
                    } mb-2">${isUser ? 'You' : 'NAMI AI'}</p>
                    <p class="text-gray-100 text-sm leading-relaxed">${content}</p>
                    ${!isUser ? `
                    <div class="mt-3 flex gap-3">
                        <button onclick="speakText('${escapedContent}')" 
                            class="text-gray-400 hover:text-white transition-colors">
                            <i class="fas fa-volume-up text-xs"></i>
                        </button>
                        <button onclick="copyToClipboard('${escapedContent}')" 
                            class="text-gray-400 hover:text-white transition-colors">
                            <i class="fas fa-copy text-xs"></i>
                        </button>
                    </div>` : ''}
                </div>
            </div>
        </div>
    `;
    return messageDiv;
}

// Core Functionality
async function fetchAnswer(question) {
    toggleLoading(true);
    abortController = new AbortController();
    
    try {
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: "llama-3.3-70b-versatile", // Current recommended model
                messages: [{ role: "user", content: question }],
                temperature: 0.3,
                max_tokens: 512,
                top_p: 0.9
            }),
            signal: abortController.signal
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
        }
        
        const data = await response.json();
        const answer = data.choices[0]?.message?.content;
        
        if (!answer) throw new Error('No answer received from the API');
        
        document.getElementById('conversationContainer').appendChild(
            createMessageElement(answer, false)
        );
        scrollToBottom();
        speakText(answer);
    } catch (error) {
        if (error.name !== 'AbortError') {
            console.error('Error:', error);
            showError(error.message || 'Failed to get response. Please try again.');
        }
    } finally {
        toggleLoading(false);
    }
}

// Voice Control Functions
function togglePause() {
    if (!synthesis) return;
    
    if (isPaused) {
        synthesis.resume();
        document.getElementById('pauseButton').innerHTML = '<i class="fas fa-pause text-gray-300"></i>';
        isPaused = false;
        document.getElementById('statusText').textContent = "Speaking...";
    } else {
        synthesis.pause();
        document.getElementById('pauseButton').innerHTML = '<i class="fas fa-play text-gray-300"></i>';
        isPaused = true;
        document.getElementById('statusText').textContent = "Paused";
    }
}

function stopSpeaking() {
    if (synthesis && isSpeaking) {
        synthesis.cancel();
        isSpeaking = false;
        isPaused = false;
        document.getElementById('pauseButton').innerHTML = '<i class="fas fa-pause text-gray-300"></i>';
        document.getElementById('statusText').textContent = "Ready";
        document.getElementById('micButton').querySelector('div').classList.remove('speaking-animation');
    }
}

// Voice Recognition Functions
function startListening() {
    stopSpeaking();
    
    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.onresult = (event) => {
        const question = event.results[0][0].transcript;
        document.getElementById('conversationContainer').appendChild(
            createMessageElement(question, true)
        );
        scrollToBottom();
        fetchAnswer(question);
    };

    recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        showError('Speech recognition error. Please try again.');
        isListening = false;
        document.getElementById('statusText').textContent = "Ready";
    };

    recognition.onend = () => {
        isListening = false;
        document.getElementById('statusText').textContent = "Ready";
    };

    recognition.start();
    isListening = true;
    document.getElementById('statusText').textContent = "Listening...";
}

function stopListening() {
    if (recognition) {
        recognition.stop();
    }
    isListening = false;
    document.getElementById('statusText').textContent = "Ready";
}

function toggleListening() {
    if (isListening) {
        stopListening();
    } else {
        startListening();
    }
}

// Utility Functions
function showError(message) {
    const errorDiv = document.createElement('div');
    errorDiv.className = 'w-full p-3 bg-red-800/50 rounded-lg backdrop-blur-sm animate-fade-in-up';
    errorDiv.innerHTML = `
        <div class="flex items-center gap-2 text-red-300">
            <i class="fas fa-exclamation-circle"></i>
            <p class="text-sm">${message}</p>
        </div>
    `;
    document.getElementById('conversationContainer').appendChild(errorDiv);
    scrollToBottom();
}

function stopResponse() {
    abortController.abort();
    stopSpeaking();
    stopListening();
    toggleLoading(false);
}

function copyToClipboard(text) {
    navigator.clipboard.writeText(text).then(() => {
        const alert = document.createElement('div');
        alert.className = 'fixed bottom-4 left-1/2 -translate-x-1/2 px-4 py-2 bg-gray-800/90 text-white rounded-full text-sm backdrop-blur-sm animate-fade-in';
        alert.textContent = 'Copied to clipboard!';
        document.body.appendChild(alert);
        setTimeout(() => alert.remove(), 2000);
    }).catch(err => {
        console.error('Failed to copy text: ', err);
    });
}

function speakText(text) {
    stopSpeaking();
    
    if (!synthesis) {
        synthesis = window.speechSynthesis;
    }
    
    const utterance = new SpeechSynthesisUtterance(text);
    
    utterance.onstart = () => {
        isSpeaking = true;
        isPaused = false;
        document.getElementById('statusText').textContent = "Speaking...";
        document.getElementById('micButton').querySelector('div').classList.add('speaking-animation');
    };

    utterance.onend = () => {
        isSpeaking = false;
        isPaused = false;
        document.getElementById('statusText').textContent = "Ready";
        document.getElementById('micButton').querySelector('div').classList.remove('speaking-animation');
    };

    utterance.onerror = (event) => {
        console.error('Speech synthesis error:', event);
        isSpeaking = false;
        isPaused = false;
        document.getElementById('statusText').textContent = "Ready";
        document.getElementById('micButton').querySelector('div').classList.remove('speaking-animation');
    };

    // Try to find a pleasant voice
    const voices = synthesis.getVoices();
    if (voices.length > 0) {
        const preferredVoices = voices.filter(v => v.name.includes('Female') || v.name.includes('Zira') || v.name.includes('Google UK Female'));
        utterance.voice = preferredVoices.length > 0 ? preferredVoices[0] : voices[0];
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
    }

    synthesis.speak(utterance);
}

// Initialize
window.addEventListener('load', () => {
    synthesis = window.speechSynthesis;
    
    // Load voices properly
    if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = () => {
            console.log('Voices loaded');
        };
    }
    
    // Some browsers need this to load voices
    setTimeout(() => {
        if (synthesis.getVoices().length === 0) {
            synthesis.getVoices();
        }
    }, 1000);
    
    // Initialize status
    document.getElementById('statusText').textContent = "Ready";
});
    </script>
</body>
</html>